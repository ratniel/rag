# TODO: Delete nodes with length less than 100
# TODO: Add emebeddings to each node
# TODO: Append summary produced by gemini to text for better generation (summary + text)

import os
import pickle
import time
from typing import List

import google.generativeai as genai
from dotenv import load_dotenv
from google.generativeai import GenerationConfig
from llama_index.core.schema import TextNode
from llama_index.embeddings.gemini import GeminiEmbedding
from tqdm import tqdm

from src.indexing_utils import load_docs, save_docstore
from ved_src.utils import make_prompt
from src.discord_utils import send_msg

# TODO: add fixed path in load_dotenv
load_dotenv()


def add_summary_to_nodes(nodes: List[TextNode]):
    """Adds summary of node.text generated by the Gemini API into metadata (node.metadata['summary']).
    Stores the response of the last node processed into a pickle file.
    Finally, stores the summarised nodes into a docstore

    Args:
        nodes: list of nodes to include summary in the metadata
    """
    """Adds summary of node.text generated by the Gemini API into metadata (node.metadata['summary']).
    Stores the response of the last node processed into a pickle file.
    Finally, stores the summarised nodes into a docstore 

    Args:
        nodes: list of nodes to include summary in the metadata
    """
    config = GenerationConfig(
        # max_output_tokens = 600,
        temperature=0.6,
        top_p=1,
        top_k=1,
    )

    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]

    model = genai.GenerativeModel(
        "gemini-pro", generation_config=config, safety_settings=safety_settings
    )
    try:
        for node in tqdm(nodes, desc="Processing nodes", unit="node", total=len(nodes)):
            prompt = make_prompt(node.text)

            answer = model.generate_content(prompt)
            node.metadata["summary"] = answer.text
            time.sleep(3)
        send_msg("Summary added successfully!")
        return nodes
    except Exception as e:  # noqa: F841
        send_msg(
            f"Error occured while context addition in file_node:{node.metadata['file_name'], node.id_}"
        )
        with open("gemini_response.pkl", "wb") as pickle_file:
            pickle.dump(answer, pickle_file)


def delete_short_nodes(nodes: List[TextNode], min_length: int = 100):
    nodes = [node for node in nodes if len(node.text) > min_length]
    return nodes


def embed_nodes(
    nodes: List[TextNode], docstore_name: str = None, save_to_docstore: bool = False
):
    embed_model = GeminiEmbedding(
        model_name="models/embedding-001", api_key=os.environ.get("GOOGLE_API_KEY")
    )
    for node in tqdm(nodes, desc="Processing nodes", total=len(nodes), unit="node"):
        node.embedding = embed_model.get_text_embedding(node.metadata["summary"])
    if save_to_docstore is True and docstore_name is None:
        raise ValueError("docstore_name is not provided")
    # save nodes to docstore
    if save_to_docstore is True:
        save_docstore(nodes, "./storage/docstore", docstore_name)
    send_msg("Nodes embedded successfully!")
    return nodes


def combine_summary_text(nodes: List[TextNode]):
    for node in nodes:
        node.text = node.metadata["summary"] + " " + node.text
    return nodes


if __name__ == "__main__":
    nodes = load_docs("./storage/docstore/summary_nodes", return_docstore=False)
    embed_nodes(nodes)
