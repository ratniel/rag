{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 594/594 [00:00<00:00, 7141.12file/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c45aeb7d0764f31928c6cc8e3e186b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import HTMLNodeParser\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"/home/dai/33/project/rag/data/clean_html\",\n",
    "                                  recursive=True)\n",
    "\n",
    "documents = reader.load_data(show_progress=True)\n",
    "node_parser = HTMLNodeParser(tags = [\"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"li\", \"b\", \"i\", \"u\", \"section\", \"text\", \"title\"])\n",
    "nodes = node_parser.get_nodes_from_documents(documents, show_progress=True)\n",
    "nodes = [node for node in nodes if len(node.get_content()) > 0]\n",
    "for node in nodes:\n",
    "    #remove all the \\n and \\t\n",
    "    node.text = node.text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc3082edc22491492c383b6986d6a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/5031 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "\n",
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[2048]\n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(nodes, show_progress=True)\n",
    "nodes = [node for node in nodes if len(node.get_content()) > 0]\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2110"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater_size_docs = []\n",
    "for i in range(len(nodes)):\n",
    "    size = nodes[i].metadata['file_size']\n",
    "    if size > 10000:\n",
    "        greater_size_docs.append(nodes[i].metadata['file_name'])\n",
    "\n",
    "len(greater_size_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bdebb2dfb14beda81ce21834301701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902da17eba19413aa543717dc9dbb133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Request payload size exceeds the limit: 10000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/dai/33/project/rag/temp.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/33/project/rag/temp.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Settings\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/33/project/rag/temp.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Settings\u001b[39m.\u001b[39membed_model \u001b[39m=\u001b[39m GeminiEmbedding(model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodels/embedding-001\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dai/33/project/rag/temp.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m index \u001b[39m=\u001b[39m VectorStoreIndex(nodes\u001b[39m=\u001b[39;49mnodes, embed_model\u001b[39m=\u001b[39;49mSettings\u001b[39m.\u001b[39;49membed_model, show_progress\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:74\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embed_model \u001b[39m=\u001b[39m (\n\u001b[1;32m     68\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[39m=\u001b[39mcallback_manager)\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m embed_model\n\u001b[1;32m     70\u001b[0m     \u001b[39melse\u001b[39;00m embed_model_from_settings_or_context(Settings, service_context)\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insert_batch_size \u001b[39m=\u001b[39m insert_batch_size\n\u001b[0;32m---> 74\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     75\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[1;32m     76\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[1;32m     77\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[1;32m     78\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[1;32m     79\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m     80\u001b[0m     objects\u001b[39m=\u001b[39;49mobjects,\n\u001b[1;32m     81\u001b[0m     callback_manager\u001b[39m=\u001b[39;49mcallback_manager,\n\u001b[1;32m     82\u001b[0m     transformations\u001b[39m=\u001b[39;49mtransformations,\n\u001b[1;32m     83\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     84\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/core/indices/base.py:91\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     nodes \u001b[39m=\u001b[39m nodes \u001b[39mor\u001b[39;00m []\n\u001b[0;32m---> 91\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(\n\u001b[1;32m     92\u001b[0m         nodes \u001b[39m+\u001b[39;49m objects  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:307\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m    300\u001b[0m     node\u001b[39m.\u001b[39mget_content(metadata_mode\u001b[39m=\u001b[39mMetadataMode\u001b[39m.\u001b[39mEMBED) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes\n\u001b[1;32m    301\u001b[0m ):\n\u001b[1;32m    302\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot build index from nodes with no content. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure all nodes have content.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 307\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minsert_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:279\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     run_async_tasks(tasks)\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(\n\u001b[1;32m    280\u001b[0m         index_struct,\n\u001b[1;32m    281\u001b[0m         nodes,\n\u001b[1;32m    282\u001b[0m         show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress,\n\u001b[1;32m    283\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minsert_kwargs,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:232\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mfor\u001b[39;00m nodes_batch \u001b[39min\u001b[39;00m iter_batch(nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insert_batch_size):\n\u001b[0;32m--> 232\u001b[0m     nodes_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_with_embedding(nodes_batch, show_progress)\n\u001b[1;32m    233\u001b[0m     new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39madd(nodes_batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minsert_kwargs)\n\u001b[1;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mstores_text \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override:\n\u001b[1;32m    236\u001b[0m         \u001b[39m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[1;32m    237\u001b[0m         \u001b[39m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:140\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_with_embedding\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_node_with_embedding\u001b[39m(\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    131\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[1;32m    132\u001b[0m     show_progress: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    133\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseNode]:\n\u001b[1;32m    134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m \u001b[39m    Allows us to store these nodes in a vector store.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m    Embeddings are called in batches.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     id_to_embed_map \u001b[39m=\u001b[39m embed_nodes(\n\u001b[1;32m    141\u001b[0m         nodes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_model, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     results \u001b[39m=\u001b[39m []\n\u001b[1;32m    145\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/core/indices/utils.py:137\u001b[0m, in \u001b[0;36membed_nodes\u001b[0;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         id_to_embed_map[node\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39membedding\n\u001b[0;32m--> 137\u001b[0m new_embeddings \u001b[39m=\u001b[39m embed_model\u001b[39m.\u001b[39;49mget_text_embedding_batch(\n\u001b[1;32m    138\u001b[0m     texts_to_embed, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[1;32m    142\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/core/base/embeddings/base.py:255\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[0;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(cur_batch) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_batch_size:\n\u001b[1;32m    250\u001b[0m     \u001b[39m# flush\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m    252\u001b[0m         CBEventType\u001b[39m.\u001b[39mEMBEDDING,\n\u001b[1;32m    253\u001b[0m         payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mSERIALIZED: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict()},\n\u001b[1;32m    254\u001b[0m     ) \u001b[39mas\u001b[39;00m event:\n\u001b[0;32m--> 255\u001b[0m         embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch)\n\u001b[1;32m    256\u001b[0m         result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n\u001b[1;32m    257\u001b[0m         event\u001b[39m.\u001b[39mon_end(\n\u001b[1;32m    258\u001b[0m             payload\u001b[39m=\u001b[39m{\n\u001b[1;32m    259\u001b[0m                 EventPayload\u001b[39m.\u001b[39mCHUNKS: cur_batch,\n\u001b[1;32m    260\u001b[0m                 EventPayload\u001b[39m.\u001b[39mEMBEDDINGS: embeddings,\n\u001b[1;32m    261\u001b[0m             },\n\u001b[1;32m    262\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/embeddings/gemini/base.py:80\u001b[0m, in \u001b[0;36mGeminiEmbedding._get_text_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_text_embeddings\u001b[39m(\u001b[39mself\u001b[39m, texts: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[\u001b[39mfloat\u001b[39m]]:\n\u001b[1;32m     79\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get text embeddings.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     81\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49membed_content(\n\u001b[1;32m     82\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     83\u001b[0m             content\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m     84\u001b[0m             title\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtitle,\n\u001b[1;32m     85\u001b[0m             task_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask_type,\n\u001b[1;32m     86\u001b[0m         )[\u001b[39m\"\u001b[39;49m\u001b[39membedding\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     87\u001b[0m         \u001b[39mfor\u001b[39;49;00m text \u001b[39min\u001b[39;49;00m texts\n\u001b[1;32m     88\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/llama_index/embeddings/gemini/base.py:81\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_text_embeddings\u001b[39m(\u001b[39mself\u001b[39m, texts: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[\u001b[39mfloat\u001b[39m]]:\n\u001b[1;32m     79\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get text embeddings.\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m---> 81\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49membed_content(\n\u001b[1;32m     82\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     83\u001b[0m             content\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m     84\u001b[0m             title\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtitle,\n\u001b[1;32m     85\u001b[0m             task_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask_type,\n\u001b[1;32m     86\u001b[0m         )[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     87\u001b[0m         \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts\n\u001b[1;32m     88\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/generativeai/embedding.py:164\u001b[0m, in \u001b[0;36membed_content\u001b[0;34m(model, content, task_type, title, client)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     embedding_request \u001b[39m=\u001b[39m glm\u001b[39m.\u001b[39mEmbedContentRequest(\n\u001b[1;32m    162\u001b[0m         model\u001b[39m=\u001b[39mmodel, content\u001b[39m=\u001b[39mcontent_types\u001b[39m.\u001b[39mto_content(content), task_type\u001b[39m=\u001b[39mtask_type, title\u001b[39m=\u001b[39mtitle\n\u001b[1;32m    163\u001b[0m     )\n\u001b[0;32m--> 164\u001b[0m     embedding_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49membed_content(embedding_request)\n\u001b[1;32m    165\u001b[0m     embedding_dict \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(embedding_response)\u001b[39m.\u001b[39mto_dict(embedding_response)\n\u001b[1;32m    166\u001b[0m     embedding_dict[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m embedding_dict[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:968\u001b[0m, in \u001b[0;36mGenerativeServiceClient.embed_content\u001b[0;34m(self, request, model, content, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(metadata) \u001b[39m+\u001b[39m (\n\u001b[1;32m    964\u001b[0m     gapic_v1\u001b[39m.\u001b[39mrouting_header\u001b[39m.\u001b[39mto_grpc_metadata(((\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mmodel),)),\n\u001b[1;32m    965\u001b[0m )\n\u001b[1;32m    967\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 968\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m    969\u001b[0m     request,\n\u001b[1;32m    970\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m    971\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    972\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    973\u001b[0m )\n\u001b[1;32m    975\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    294\u001b[0m     target,\n\u001b[1;32m    295\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    296\u001b[0m     sleep_generator,\n\u001b[1;32m    297\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    298\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    299\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[39m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[1;32m    154\u001b[0m         exc,\n\u001b[1;32m    155\u001b[0m         deadline,\n\u001b[1;32m    156\u001b[0m         sleep,\n\u001b[1;32m    157\u001b[0m         error_list,\n\u001b[1;32m    158\u001b[0m         predicate,\n\u001b[1;32m    159\u001b[0m         on_error,\n\u001b[1;32m    160\u001b[0m         exception_factory,\n\u001b[1;32m    161\u001b[0m         timeout,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[39m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[39m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[39m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mraise\u001b[39;00m final_exc \u001b[39mfrom\u001b[39;00m \u001b[39msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m on_error_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[39m=\u001b[39m target()\n\u001b[1;32m    145\u001b[0m         \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout \u001b[39m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag3/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Request payload size exceeds the limit: 10000 bytes."
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = GeminiEmbedding(model_name='models/embedding-001')\n",
    "\n",
    "index = VectorStoreIndex(nodes=nodes, embed_model=Settings.embed_model, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
