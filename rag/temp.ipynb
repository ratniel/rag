{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:   0%|          | 0/594 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 594/594 [00:00<00:00, 4154.66file/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3596cddbddf24c64a68e3ed79a56a5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import HTMLNodeParser\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"/home/dai/35/rag/data/clean_html\",\n",
    "                                  recursive=True)\n",
    "\n",
    "documents = reader.load_data(show_progress=True)\n",
    "node_parser = HTMLNodeParser(tags = [\"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"li\", \"b\", \"i\", \"u\", \"section\", \"text\", \"title\"])\n",
    "nodes = node_parser.get_nodes_from_documents(documents, show_progress=True)\n",
    "nodes = [node for node in nodes if len(node.get_content()) > 0]\n",
    "for node in nodes:\n",
    "    #remove all the \\n and \\t\n",
    "    node.text = node.text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a38bacd4ad94989a50ac2da7fcc7d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/45914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=2048, chunk_overlap=40)\n",
    "nodes = splitter.get_nodes_from_documents(nodes, show_progress=True)\n",
    "nodes = [node for node in nodes if len(node.get_content()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement ingestion pipeline and combine two node parser together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'capacities as advisors, authors, owners of photographs and clips,\\ntesters etc.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[2].get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "embedding = GeminiEmbedding()\n",
    "for i, node in enumerate(nodes):\n",
    "    print(str(i)+\"\\r\", end=\"\", flush=True)\n",
    "    try:\n",
    "        embedding.get_text_embedding(node.get_content())\n",
    "    except Exception as e:\n",
    "        print(len(node.get_content()))\n",
    "        print(node.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futher implementation guide\n",
    "```python\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "\n",
    "pipeline = IngestionPipeline(transformations=[TokenTextSplitter(), ...])\n",
    "\n",
    "nodes = pipeline.run(documents=documents)\n",
    "```\n",
    "\n",
    "```python\n",
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=10)\n",
    "\n",
    "# global\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.text_splitter = text_splitter\n",
    "\n",
    "# per-index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, transformations=[text_splitter]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(documents, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
