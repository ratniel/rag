{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LlamaIndex with gemini embeddings and gemini model\n",
        "\n",
        "- No Chunking is applied which is considering each file as a single document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, load_index_from_storage\n",
        "from llama_index.embeddings.gemini import GeminiEmbedding\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.embed_model = GeminiEmbedding(model_name='models/embedding-001')\n",
        "Settings.llm = Gemini(model_name='models/gemini-pro', temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_reader_path = \"/home/dai/33/project/rag/data/clean_text\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe029c65754a4617a8ea9edd8013a595",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing nodes:   0%|          | 0/594 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ee6fdff90254cdab27ef170371cfda4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/1413 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# setting the current filename\n",
        "filename = \"gemini_no_chunking\"\n",
        "\n",
        "# check if storage already exists\n",
        "PERSIST_DIR = f\"./storage/{filename}\"\n",
        "\n",
        "if not os.path.exists(PERSIST_DIR):\n",
        "    # load the documents and create the index\n",
        "    documents = SimpleDirectoryReader(data_reader_path, recursive=True).load_data()\n",
        "    index = VectorStoreIndex.from_documents(documents, embed_model=Settings.embed_model, show_progress=True)\n",
        "    \n",
        "    # store it for later\n",
        "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "else:\n",
        "    print(f\"{PERSIST_DIR} already exists.\\n Indexes loading...\")\n",
        "    # load the existing index\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
        "    index = load_index_from_storage(storage_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wZh5PnWewN0Y"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine(llm=Settings.llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1e95uexP0nUH",
        "outputId": "c534de1e-67bb-49e3-e885-0e2257eb0f66"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\"What are the benefits of Abhyanga?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Response: Abhyanga has the following benefits: Balya, Jvarahara,\n",
            "Maardavakara, Nidraakara, Preen`ana, Pusht`ikrit, S`hramahara,\n",
            "Varn`ya, Vayasthaapana, Vran`a Ropan`a, Vran`a S`hodhana, Vrishya\n",
            "______________________________________________________________________\n",
            "Source Node 1/2\n",
            "Node ID: f06685ed-153a-4dc7-b7dc-0ba59d0aa26e\n",
            "Similarity: 0.7477792254562072\n",
            "Text: Vyaapad --) Vamana Ayoga Arha Vyaadhi,Vyaapad --) Vamana-\n",
            "Virechana Vyaapad --) Aadhmaana Arha Vyaadhi,Vyaapad --) Vamana-\n",
            "Virechana Vyaapad --) Hridayopasaran`a Arha Vyaadhi,Vyaapad --)\n",
            "Vamana-Virechana Vyaapad --) Udaavarta Arha Vyaadhi,Vyaapad --)\n",
            "Vamana-Virechana Vyaapad --) Vaatas`hoola Arha Vyaadhi,Vyaapad --)\n",
            "Virechana Ayoga Anarha Vyaadhi ...\n",
            "______________________________________________________________________\n",
            "Source Node 2/2\n",
            "Node ID: 0454fc79-4bbe-4490-b1ff-3713de7689ca\n",
            "Similarity: 0.7305946587932739\n",
            "Text: Abhyanga             Abhyanga     Chikitsaa Karma,Abhyanga\n",
            "Specific Classification,Snehana Instruments used,Deepaka Instruments\n",
            "used,Taila Paatra Instruments used,Vastra Gun`a,Drava Gun`a,Snigdha\n",
            "Gun`a,Sookshma Gun`a,Sthira Gun`a,Ushn`a Karma,Balya Karma,Jvarahara\n",
            "Karma,Maardavakara Karma,Nidraakara Karma,Preen`ana Karma,Pusht`ikrit\n",
            "Karma,S`hram...\n"
          ]
        }
      ],
      "source": [
        "from llama_index.legacy.response.pprint_utils import pprint_response\n",
        "pprint_response(response,show_source=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
